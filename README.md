Paper zur Robustheit / Sensitivität von VLMich nutze den Ort mal um zusammenzutragen, was wir in dem Paper machen wollen, was schon erledigt ist und was noch fehlt:

Modelle:

* CLIP - OpenAI - 2021
* PaliGemma - Google - 2024 (https://huggingface.co/google/paligemma-3b-mix-224) 
* Phi-3.5 Vision - Microsoft - 2024 (https://huggingface.co/microsoft/Phi-3.5-vision-instruct)
* Qwen-VL - Alibaba - 2023 (https://github.com/QwenLM/Qwen-VL?tab=readme-ov-file#qwen-vl-plus)


Datensätze (Vorschläge - Auswahl)

* MVTec AD: Bilder zur Erkennung von Anomalien und Defekten in industriellen Produkten: https://www.mvtec.com/company/research/datasets/mvtec-ad
* MedMNIST: Sammlung medizinischer Bilddatensätze für verschiedene Klassifikationsaufgaben: https://medmnist.com/
* BreakHis: Histopathologische Bilder von Brustkrebs zur gutartigen und bösartigen Klassifikation: https://www.kaggle.com/datasets/paultimothymooney/breast-histopathology-images
* CropDisease: Bilder zur Klassifikation von Pflanzenkrankheiten in verschiedenen Kulturen: https://www.kaggle.com/datasets/emmarex/plantdisease
* FER2013: Bilder von Gesichtern zur Klassifikation in emotionale Kategorien: https://www.kaggle.com/datasets/msambare/fer2013
* EuroSAT: Satellitenbilder zur Klassifikation von Landbedeckungsklassen: https://zenodo.org/records/7711810#.ZAm3k-zMKEA
* Food-101: Bilder von 101 verschiedenen Lebensmittelkategorien zur Klassifikation: https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/

